{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FrozenLake.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyM/koQnqH8zr879tm99Uw+O",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/odarasimi/FrozenLake/blob/main/FrozenLake.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ajwI5l6ozI-7"
      },
      "source": [
        "import numpy as np\n",
        "import gym\n",
        "import random\n",
        "import time\n",
        "from IPython.display import clear_output"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iq4WyR_vzowu"
      },
      "source": [
        "env = gym.make(\"FrozenLake-v0\")"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bHeJTc4Xz595"
      },
      "source": [
        "action_space_size = env.action_space.n\n",
        "state_space_size = env.observation_space.n\n",
        "\n",
        "q_table = np.zeros((state_space_size,action_space_size))"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yl2mY5qo0YHu",
        "outputId": "1d22aa37-b4ef-4089-8ca0-f18068ad3cc1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "q_table.shape"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(16, 4)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JVvlbmd20Zw8"
      },
      "source": [
        "num_episodes = 10000\n",
        "max_steps_per_episode = 150\n",
        "\n",
        "learning_rate = 0.1\n",
        "discount_rate = 1\n",
        "\n",
        "exploration_rate = 1\n",
        "max_exploration_rate = 1\n",
        "min_exploration_rate = 0.01\n",
        "exploration_decay_rate = 0.001"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "76uMCdjZ2Iol"
      },
      "source": [
        "**Algorithm**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v0VADo7b2usj"
      },
      "source": [
        "rewards_all_episodes = []\n",
        "\n",
        "for episode in range(num_episodes):\n",
        "  state = env.reset()\n",
        "  done = False\n",
        "  rewards_current_episode = 0\n",
        " \n",
        "  for step in range(max_steps_per_episode):\n",
        "    exploration_rate_threshold = random.uniform(0, 1)\n",
        "\n",
        "    if exploration_rate_threshold > exploration_rate:\n",
        "      action = np.argmax(q_table[state,:]) \n",
        "    else:\n",
        "      action = env.action_space.sample()\n",
        " \n",
        "      new_state, reward, done, info = env.step(action)\n",
        " \n",
        "      q_table[state, action] = q_table[state, action] * (1 - learning_rate) + learning_rate * (reward + discount_rate * np.max(q_table[new_state, :]))\n",
        "      \n",
        "      state = new_state\n",
        " \n",
        "      rewards_current_episode += reward\n",
        "      \n",
        "      if done == True: \n",
        "        break\n",
        "  exploration_rate = min_exploration_rate + (max_exploration_rate - min_exploration_rate) * np.exp(-exploration_decay_rate*episode)\n",
        "  rewards_all_episodes.append(rewards_current_episode)"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "isMPHglrZHzA",
        "outputId": "080cdedf-6c7b-415b-edc5-531acf71d72e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "q_table"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.78525556, 0.7801119 , 0.77945089, 0.77571327],\n",
              "       [0.35811108, 0.36399266, 0.45525812, 0.76778302],\n",
              "       [0.67444899, 0.67660265, 0.65352834, 0.74366533],\n",
              "       [0.49403561, 0.48059575, 0.52555893, 0.71223892],\n",
              "       [0.78524423, 0.60304171, 0.47072267, 0.72746553],\n",
              "       [0.        , 0.        , 0.        , 0.        ],\n",
              "       [0.43720153, 0.2362869 , 0.51065793, 0.27129287],\n",
              "       [0.        , 0.        , 0.        , 0.        ],\n",
              "       [0.36607844, 0.55109198, 0.43547485, 0.78518547],\n",
              "       [0.55644092, 0.78520972, 0.64302211, 0.50615117],\n",
              "       [0.74053473, 0.58150491, 0.53989515, 0.49834433],\n",
              "       [0.        , 0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        ],\n",
              "       [0.48180609, 0.50121995, 0.85769482, 0.53875866],\n",
              "       [0.82917948, 0.91918442, 0.87576709, 0.84346274],\n",
              "       [0.        , 0.        , 0.        , 0.        ]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l4zzHsGe3-13",
        "outputId": "822a1162-3836-4ef0-e45d-df77a46fdf6a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "for episode in range(3):\n",
        "  state = env.reset()\n",
        "  done = False\n",
        "  print(\"EPISODE \", episode+1, \"\\n\\n\\n\\n\")\n",
        "  time.sleep(1)\n",
        "\n",
        "  for step in range(max_steps_per_episode):        \n",
        "    clear_output(wait=True)\n",
        "    env.render()\n",
        "    time.sleep(1)\n",
        "\n",
        "    action = np.argmax(q_table[state,:])        \n",
        "    new_state, reward, done, info = env.step(action)\n",
        "      \n",
        "    if done:\n",
        "      clear_output(wait=True)\n",
        "      env.render()\n",
        "\n",
        "      if reward == 1:\n",
        "        print(\"...Suarez reached the goal!\")\n",
        "        time.sleep(3)\n",
        "      else:\n",
        "        print(\"...Suarez fell through a hole!\")\n",
        "        time.sleep(3)\n",
        "        clear_output(wait=True)\n",
        "      break\n",
        "\n",
        "    state = new_state\n",
        "\n",
        "env.close()   "
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  (Right)\n",
            "SFFF\n",
            "FHFH\n",
            "FFFH\n",
            "HFF\u001b[41mG\u001b[0m\n",
            "...Suarez reached the goal!\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}